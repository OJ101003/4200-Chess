{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37164639\n",
      "b'CAAAAAAAAAAQAAAAAAAAAIEAAAAAAAAAJAAAAAAAAABCAAAAAAAAAADvABAAAAAAAAAAAAAAAAgAAAAAAAAAEAAAAAAAAACBAAAAAAAAACQAAAAAAAAAQgAAAAAAAP8AAAABEz8='\n"
     ]
    }
   ],
   "source": [
    "from peewee import *\n",
    "import base64\n",
    "\n",
    "db = SqliteDatabase(\"test.db\")\n",
    "\n",
    "class Evaluations(Model):\n",
    "  id = IntegerField()\n",
    "  fen = TextField()\n",
    "  binary = BlobField()\n",
    "  eval = FloatField()\n",
    "\n",
    "  class Meta:\n",
    "    database = db\n",
    "\n",
    "  def binary_base64(self):\n",
    "    return base64.b64encode(self.binary)\n",
    "db.connect()\n",
    "LABEL_COUNT = 37164639\n",
    "print(LABEL_COUNT)\n",
    "eval = Evaluations.get(Evaluations.id == 1)\n",
    "print(eval.binary_base64())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, IterableDataset, random_split\n",
    "import pytorch_lightning as pl\n",
    "from random import randrange\n",
    "\n",
    "\n",
    "class EvaluationDataset(IterableDataset):\n",
    "  def __init__(self, count):\n",
    "    self.count = count\n",
    "  def __iter__(self):\n",
    "    return self\n",
    "  def __next__(self):\n",
    "    idx = randrange(self.count)\n",
    "    return self[idx]\n",
    "  def __len__(self):\n",
    "    return self.count\n",
    "  def __getitem__(self, idx):\n",
    "    eval = Evaluations.get(Evaluations.id == idx+1)\n",
    "    bin = np.frombuffer(eval.binary, dtype=np.uint8)\n",
    "    bin = np.unpackbits(bin, axis=0).astype(np.single) \n",
    "    eval.eval = max(eval.eval, -15)\n",
    "    eval.eval = min(eval.eval, 15)\n",
    "    ev = np.array([eval.eval]).astype(np.single) \n",
    "    return {'binary':bin, 'eval':ev}    \n",
    "\n",
    "dataset = EvaluationDataset(count=LABEL_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start tensorboard.\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',  # Replace 'val_loss' with your validation metric\n",
    "    dirpath = 'lightning_logs/chessml',\n",
    "    filename='{epoch}-{val_loss:.2f}',  # Save files as epoch number and validation loss\n",
    "    every_n_epochs=1,  # Save every epoch\n",
    "    mode='min',  # 'min' if the metric should decrease (e.g., loss), 'max' for accuracy\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Python311\\Lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:653: Checkpoint directory C:\\Users\\hacke\\Documents\\GitHub\\4200-Chess\\lightning_logs\\chessml exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type       | Params\n",
      "------------------------------------\n",
      "0 | seq  | Sequential | 2.0 M \n",
      "------------------------------------\n",
      "2.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 M     Total params\n",
      "7.847     Total estimated model params size (MB)\n",
      "c:\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "c:\\Python311\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:121: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 72588/72588 [3:50:20<00:00,  5.25it/s, v_num=nt-4]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:383: `ModelCheckpoint(monitor='val_loss')` could not find the monitored key in the returned metrics: ['train_loss', 'epoch', 'step']. HINT: Did you call `log('val_loss', value)` in the `LightningModule`?\n",
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 72588/72588 [3:50:20<00:00,  5.25it/s, v_num=nt-4]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "class EvaluationModel(pl.LightningModule):\n",
    "  def __init__(self,learning_rate=1e-3,batch_size=1024,layer_count=10):\n",
    "    super().__init__()\n",
    "    self.batch_size = batch_size\n",
    "    self.learning_rate = learning_rate\n",
    "    layers = []\n",
    "    for i in range(layer_count-1):\n",
    "      layers.append((f\"linear-{i}\", nn.Linear(808, 808)))\n",
    "      layers.append((f\"relu-{i}\", nn.ReLU()))\n",
    "    layers.append((f\"linear-{layer_count-1}\", nn.Linear(808, 1)))\n",
    "    self.seq = nn.Sequential(OrderedDict(layers))\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.seq(x)\n",
    "\n",
    "  def training_step(self, batch, batch_idx):\n",
    "    x, y = batch['binary'], batch['eval']\n",
    "    y_hat = self(x)\n",
    "    loss = F.l1_loss(y_hat, y)\n",
    "    self.log(\"train_loss\", loss)\n",
    "    return loss\n",
    "\n",
    "  def configure_optimizers(self):\n",
    "    return torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "\n",
    "  def train_dataloader(self):\n",
    "    dataset = EvaluationDataset(count=LABEL_COUNT)\n",
    "    return DataLoader(dataset, batch_size=self.batch_size, num_workers=0, pin_memory=True)  # Adjust num_workers as per your CPU\n",
    "\n",
    "configs = [\n",
    "           {\"layer_count\": 4, \"batch_size\": 512},\n",
    "          #  {\"layer_count\": 6, \"batch_size\": 1024},\n",
    "           ]\n",
    "for config in configs:\n",
    "    version_name = f'{int(time.time())}-batch_size-{config[\"batch_size\"]}-layer_count-{config[\"layer_count\"]}'\n",
    "    logger = TensorBoardLogger(\"lightning_logs\", name=\"chessml\", version=version_name)\n",
    "    trainer = pl.Trainer(accelerator=\"auto\", precision=\"16-mixed\", max_epochs=1,  logger=logger, callbacks = [checkpoint_callback])\n",
    "    model = EvaluationModel(layer_count=config[\"layer_count\"], batch_size=config[\"batch_size\"])\n",
    "    # Uncomment and use the learning rate finder if needed.\n",
    "    trainer.fit(model)\n",
    "    # Remove break if iterating through multiple configs.\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
